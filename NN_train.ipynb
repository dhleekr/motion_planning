{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx2QN_cOte-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3e1907-5bb2-4ea7-9cea-6ce1d0327b59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGAwzWU5tjA1",
        "outputId": "1311f56b-292c-4396-afab-97bad1cf5ba2"
      },
      "source": [
        "cd /content/drive/MyDrive/motion planning/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/motion planning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGKyvOeRtjXI"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EHt8lspFLA0",
        "outputId": "5bffffa1-9b33-4de0-9b36-f76c889f6826"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnUOuTQj29d-"
      },
      "source": [
        "# Data save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1dz5FUO7_QC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec9fdc8-30ee-4000-d212-646ce9205501"
      },
      "source": [
        "path = './0817/'\n",
        "np.random.seed(10)\n",
        "size = 20000\n",
        "kp_list = []\n",
        "idx = 0\n",
        "train_test_ratio = 0.8\n",
        "\n",
        "for i in range(3, 6):\n",
        "    for j in range(1, 4):\n",
        "        if j % 50 == 0:\n",
        "            print(i, j)\n",
        "        kappa = np.array(pd.read_csv(path+'{}_{}_k.csv'.format(i, j), header=None))\n",
        "        phi = np.array(pd.read_csv(path+'{}_{}_p.csv'.format(i, j), header=None))\n",
        "        s = np.array(pd.read_csv(path+'{}_{}_s.csv'.format(i, j), header=None))\n",
        "        temp = np.zeros((s.shape[0], s.shape[1]+1))\n",
        "        rnd = np.random.choice(len(kappa), size, replace=False)\n",
        "\n",
        "        for k in range(len(s)):\n",
        "            if s[k][4] == 10:\n",
        "                s[k][4] = 0\n",
        "            elif s[k][4] == 50:\n",
        "                s[k][4] = 1\n",
        "            elif s[k][4] == 100:\n",
        "                s[k][4] = 2\n",
        "            elif s[k][4] == 200:\n",
        "                s[k][4] = 3\n",
        "            elif s[k][4] == 300:\n",
        "                s[k][4] = 4\n",
        "            elif s[k][4] == 400:\n",
        "                s[k][4] = 5\n",
        "            elif s[k][4] == 500:\n",
        "                s[k][4] = 6\n",
        "            \n",
        "            temp[k] = np.append(s[k], np.array([idx]))\n",
        "\n",
        "        np.random.shuffle(temp)\n",
        "        train_temp, test_temp = np.split(temp, [int(train_test_ratio*len(temp))])\n",
        "        \n",
        "        if idx == 0:\n",
        "            train_set = train_temp\n",
        "            test_set = test_temp\n",
        "        else:\n",
        "            train_set = np.append(train_set, train_temp, axis=0)\n",
        "            test_set = np.append(test_set, test_temp, axis=0)\n",
        "\n",
        "        idx += 1\n",
        "        kp = []\n",
        "\n",
        "        for l in rnd:\n",
        "            tmp = []\n",
        "            k = kappa[l]\n",
        "            p = phi[l]\n",
        "            k = list(k)\n",
        "            k.extend(list(p))\n",
        "            kp.append(k)\n",
        "\n",
        "        kp = torch.tensor(kp, dtype=torch.float).to(device)\n",
        "        kp = kp.view((1, 1, size, 3))\n",
        "        kp_list.append(kp)\n",
        "\n",
        "# kp_list = np.array(kp_list)\n",
        "# np.save('./kp_list', kp_list)\n",
        "\n",
        "# np.random.shuffle(train_set)\n",
        "print(train_set)\n",
        "print(train_set.shape, test_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.37204912e+00  6.35453137e-01  2.28449575e+00  1.82196274e+00\n",
            "   3.00000000e+00  0.00000000e+00]\n",
            " [-2.28754061e+00 -2.82807367e+00 -2.79237705e+00  3.24517880e-01\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.55097889e+00 -1.62139176e+00  2.44396250e+00 -3.90230858e-01\n",
            "   3.00000000e+00  0.00000000e+00]\n",
            " ...\n",
            " [ 3.45127381e-01 -2.21081933e+00  2.33009882e+00 -3.30826654e-03\n",
            "   0.00000000e+00  8.00000000e+00]\n",
            " [ 1.08757893e+00  1.40933632e+00  1.91158883e+00  1.90845374e+00\n",
            "   0.00000000e+00  8.00000000e+00]\n",
            " [-5.36439146e-01 -1.34974944e+00 -2.60873297e-01  2.75435847e+00\n",
            "   1.00000000e+00  8.00000000e+00]]\n",
            "(21030, 6) (5261, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asCUPkBnswdP"
      },
      "source": [
        "train_df = pd.DataFrame(train_set)\n",
        "test_df = pd.DataFrame(test_set)\n",
        "\n",
        "train_df.to_csv('./train.csv', index=False, header=False)\n",
        "test_df.to_csv('./test.csv', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4onipH923BZn"
      },
      "source": [
        "# Data load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ear96gaMx3gO"
      },
      "source": [
        "size = 20000\n",
        "train_set = np.array(pd.read_csv('./20000/train.csv', header=None))\n",
        "test_set = np.array(pd.read_csv('./20000/test.csv', header=None))\n",
        "temp_list = np.load('./20000/kp_list.npy')\n",
        "\n",
        "kp_list = []\n",
        "for i in range(len(temp_list)):\n",
        "    kp = torch.tensor(temp_list[i], dtype=torch.float).to(device)\n",
        "    kp = kp.view((1, 1, size, 3))\n",
        "    kp_list.append(kp)\n",
        "print(kp_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csnotRpq3ImN"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz5w1oIwbC_a"
      },
      "source": [
        "class Custom_Dataset(Dataset):\n",
        "    def __init__(self, state):\n",
        "        self.x = state[:, :4]\n",
        "        self.target = state[:, 4]\n",
        "        self.idx = state[:, 5]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.tensor(self.x[index]).float()\n",
        "        y = torch.tensor(self.target[index]).float()\n",
        "        idx = torch.tensor(self.idx[index]).int()\n",
        "        \n",
        "        return x, y, idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlyFws1stw4C"
      },
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, h1, h2, h3, h4, h5, h6, output):\n",
        "        super(NN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, (1, 3)),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 8, 1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 1, 1),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.hidden1 = nn.Linear(size+4, h1)\n",
        "        self.hidden2 = nn.Linear(h1, h2)\n",
        "        self.hidden3 = nn.Linear(h2, h3)\n",
        "        self.hidden4 = nn.Linear(h3, h4)\n",
        "        self.hidden5 = nn.Linear(h4, h5)\n",
        "        self.hidden6 = nn.Linear(h5, h6)\n",
        "        self.predict = nn.Linear(h6, output)\n",
        "\n",
        "        # nn.init.xavier_uniform_(self.conv.weight)\n",
        "        # nn.init.xavier_uniform_(self.hidden1.weight)\n",
        "        # nn.init.xavier_uniform_(self.hidden2.weight)\n",
        "        # nn.init.xavier_uniform_(self.hidden3.weight)\n",
        "        # nn.init.xavier_uniform_(self.predict.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x2 = x2.view((-1,4))\n",
        "\n",
        "        x1 = self.conv(x1)\n",
        "        x1 = x1.view((-1,size))\n",
        "        v, i = torch.topk(x1, 10)\n",
        "\n",
        "        x = torch.cat([x1, x2], dim=1)\n",
        "\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        x = F.relu(self.hidden3(x))\n",
        "        x = F.relu(self.hidden4(x))\n",
        "        x = F.relu(self.hidden5(x))\n",
        "        x = F.relu(self.hidden6(x))\n",
        "        x = F.relu(self.predict(x))\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssNW4B7QMvUn"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE ,self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, (1, 3)),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 8, 1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 1, 1),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1, 8, 1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, 8, 1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, 1, (1, 3)),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(size, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.fc31 = nn.Linear(h2, h3)\n",
        "        self.fc32 = nn.Linear(h2, h3)\n",
        "        self.fc4 = nn.Linear(h3, h2)\n",
        "        self.fc5 = nn.Linear(h2, h1)\n",
        "        self.fc6 = nn.Linear(h1, size)\n",
        "\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view((-1,size))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        return self.fc31(x), self.fc32(x)\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    \n",
        "    def decode(self, z):\n",
        "        z = F.relu(self.fc4(z))\n",
        "        z = F.relu(self.fc5(z))\n",
        "        z = F.sigmoid(self.fc6(z))\n",
        "\n",
        "        return z\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MqRgCbTQcXS"
      },
      "source": [
        "# 수정해야됨\n",
        "def vae_loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctYzMJJQ8qGV"
      },
      "source": [
        "h1 = 512\n",
        "h2 = 512\n",
        "h3 = 512\n",
        "h4 = 512\n",
        "h5 = 512\n",
        "h6 = 512\n",
        "\n",
        "\n",
        "model = NN(h1, h2, h3, h4, h5, h6, output=7).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U0ZnTZSTcuI"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-8, max_lr=0.0001, step_size_up=1, step_size_down=19, gamma=0.95, mode='exp_range' , cycle_momentum=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4U093oqZRFj"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnnI7CI33EIW"
      },
      "source": [
        "def test(model, mode, verbose=False):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    \n",
        "    if mode == \"val\":\n",
        "        loader = val_loader\n",
        "        dataset = val_dataset\n",
        "    elif mode == \"test\":\n",
        "        loader = test_loader\n",
        "        dataset = test_dataset\n",
        "\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for x, y, idx in loader:\n",
        "            error = []\n",
        "            truth = []\n",
        "            x, y = x.float().to(device), y.to(device)\n",
        "            for n, index in enumerate(idx):\n",
        "                if n == 0:\n",
        "                    kps = kp_list[index]\n",
        "                else:\n",
        "                    kps = torch.cat([kps, kp_list[index]], dim=0)\n",
        "\n",
        "            predict = model(kps, x)\n",
        "            predict = torch.argmax(predict, 1)\n",
        "\n",
        "            if verbose:\n",
        "                print(\"Predict : \", predict)\n",
        "                print(\"Target : \", y)\n",
        "            \n",
        "            correct += (predict == y).sum().item()\n",
        "    \n",
        "    accuracy = 100 * float(correct) / len(dataset)\n",
        "    print('\\nTest accuracy : {:3f}%'.format(accuracy))\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyPGFSEH9P2O"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "stop = False\n",
        "\n",
        "best = []\n",
        "\n",
        "for eps in range(10000):\n",
        "\n",
        "    for fold_index, (t, v) in enumerate(kfold.split(train_set)):\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        train_data = train_set[t]\n",
        "        val_data = train_set[v]\n",
        "\n",
        "        train_dataset = Custom_Dataset(train_data)\n",
        "        val_dataset = Custom_Dataset(val_data)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset,batch_size=batch_size)\n",
        "        val_loader = DataLoader(val_dataset,batch_size=batch_size)\n",
        "\n",
        "        val_acc_max = 0\n",
        "\n",
        "        for epoch in range(3):\n",
        "            model.train()\n",
        "            print('\\n{}_{}fold_{}th epoch'.format(eps+1, fold_index+1, epoch+1))\n",
        "            # print(list(model.parameters()))\n",
        "            current_lr = lr_scheduler.get_last_lr()\n",
        "            print(\"\\nCurrent learning rate : \", current_lr)\n",
        "                \n",
        "            for i, data in enumerate(train_loader):\n",
        "                x, y, idx = data\n",
        "                x, y = x.float().to(device), y.to(device)\n",
        "                for n, index in enumerate(idx):\n",
        "                    if n == 0:\n",
        "                        kps = kp_list[index]\n",
        "                    else:\n",
        "                        kps = torch.cat([kps, kp_list[index]], dim=0)\n",
        "                # print(kps.shape)        \n",
        "\n",
        "                predict = model(kps, x)\n",
        "\n",
        "                loss = loss_func(predict, y.long())\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                loss.backward()\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                if i % 200 == 0:\n",
        "                    print('#'*100)\n",
        "                    # print('Target : {}'.format(y))\n",
        "                    # print('Predict : {}'.format(predict))\n",
        "                    print('Trian loss : {}'.format(loss))\n",
        "            \n",
        "            val_acc = test(model, 'val')\n",
        "\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            if val_acc_max < val_acc:\n",
        "                val_acc_max = val_acc\n",
        "                models = [model, val_acc_max]\n",
        "\n",
        "            if val_acc >= 85:\n",
        "                stop = True\n",
        "\n",
        "            if stop:\n",
        "                torch.save(model, f'./result/c2_{h1}_{h2}_{h3}_{h4}({val_acc}).pth')\n",
        "                break\n",
        "        if stop:\n",
        "            break\n",
        "                \n",
        "        best.append(models)\n",
        "    if stop:\n",
        "        break\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYnKJrK9n3xy"
      },
      "source": [
        "# Save Model(manually)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRbtBlWvUnvq"
      },
      "source": [
        "best = sorted(best, key=lambda x : x[1], reverse=True)\n",
        "print(best)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egcw3-rimfvG"
      },
      "source": [
        "model = best[0]\n",
        "val_acc = model[1]\n",
        "torch.save(model[0], f'./result/{\"c2\"}_{h1}_{h2}_{h3}_{h4}({val_acc}).pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gJAYfGKn6np"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_EJRwMHqiLk"
      },
      "source": [
        "model = torch.load('./result/c1_512_512_512_512_10_512_512_512(98.63333333333334)(55).pth', map_location=torch.device(device))\n",
        "print(len(test_set))\n",
        "test_dataset = Custom_Dataset(test_set)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100)\n",
        "acc = test(model, 'test', verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}